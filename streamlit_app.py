import os
import time
import streamlit as st
from dotenv import load_dotenv
import openai

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.set_page_config(page_title="ğŸŒ Global RAG System", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸŒ Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ - Intelligent Retrieval & Generation")
st.markdown("### ğŸš€ Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª + ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit")

# Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
uploaded_files = st.file_uploader("ğŸ“¤ Ø§Ø±ÙØ¹ Ù…Ø³ØªÙ†Ø¯Ø§ØªÙƒ (PDF / DOCX / TXT)",
                                  type=["pdf", "docx", "txt"], accept_multiple_files=True)

# Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
query = st.text_input("ğŸ’¡ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§:")

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª (Ù…Ø­Ø§ÙƒØ§Ø©)
def process_files(files):
    names = [f.name for f in files]
    return f"ğŸ“š ØªÙ… Ø±ÙØ¹ {len(files)} Ù…Ù„Ù: {', '.join(names)}"

# RAG Pipeline
def rag_pipeline(user_query):
    time.sleep(2)
    if not openai.api_key:
        return f"ğŸ” Ø§Ø³ØªØ¹Ù„Ø§Ù…Ùƒ: **{user_query}**\nğŸ“– Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ø±Ø¯ ØªØ¬Ø±ÙŠØ¨ÙŠ (Ù…Ø­Ø§ÙƒØ§Ø©)."
    response = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are a multilingual intelligent RAG assistant."},
            {"role": "user", "content": user_query}
        ],
        temperature=0.6,
        max_tokens=400
    )
    return response.choices[0].message["content"]

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¨Ø­Ø«
if uploaded_files:
    st.info(process_files(uploaded_files))

if st.button("ğŸš€ Ø§Ø¨Ø­Ø« Ø§Ù„Ø¢Ù†", type="primary", use_container_width=True):
    if query:
        with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."):
            answer = rag_pipeline(query)
        st.success("âœ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:")
        st.write(answer)
    else:
        st.warning("âš ï¸ Ø£Ø¯Ø®Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø£ÙˆÙ„Ø§Ù‹.")
