import streamlit as st
import time
from datetime import datetime
import re
import io
import base64

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="ğŸ¤– Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ø°ÙƒÙŠ - ØªØ­Ù„ÙŠÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Ø¯Ø¹Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Arabic:wght@400;700&display=swap');
    
    .main {
        direction: rtl;
        text-align: right;
        font-family: 'Noto Sans Arabic', sans-serif;
    }
    
    .stTextInput > div > div > input {
        direction: rtl;
        text-align: right;
    }
    
    .stTextArea > div > div > textarea {
        direction: rtl;
        text-align: right;
        font-family: 'Noto Sans Arabic', sans-serif;
    }
    
    h1, h2, h3 {
        font-family: 'Noto Sans Arabic', sans-serif;
        direction: rtl;
        text-align: right;
    }
    
    .real-content {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin: 1rem 0;
        border-right: 5px solid #FF5722;
    }
    
    .file-content {
        background: #f0f2f6;
        color: #333;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        max-height: 200px;
        overflow-y: auto;
        border: 1px solid #ddd;
    }
    
    .search-result {
        background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 0.5rem 0;
        border-left: 4px solid #2E7D32;
    }
</style>
""", unsafe_allow_html=True)

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
if 'files_content' not in st.session_state:
    st.session_state.files_content = {}

if 'processed_files' not in st.session_state:
    st.session_state.processed_files = []

if 'test_counter' not in st.session_state:
    st.session_state.test_counter = 0

if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

def extract_text_from_file(file):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª"""
    try:
        file_content = ""
        file_type = file.type
        
        if file_type == "text/plain":
            # Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª TXT
            content = file.read()
            if isinstance(content, bytes):
                # Ø¬Ø±Ø¨ Ø¹Ø¯Ø© encodings
                for encoding in ['utf-8', 'cp1256', 'iso-8859-1', 'windows-1256']:
                    try:
                        file_content = content.decode(encoding)
                        break
                    except:
                        continue
                if not file_content:
                    file_content = content.decode('utf-8', errors='ignore')
            else:
                file_content = str(content)
        
        elif file_type == "application/pdf":
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ø¨Ø³ÙŠØ· Ù…Ù† PDF
            content = file.read()
            file_content = f"Ù…Ù„Ù PDF: {file.name}\n"
            file_content += f"Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: {len(content)} Ø¨Ø§ÙŠØª\n"
            file_content += "Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„Ù‚Ø±Ø§Ø¡Ø© PDF Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ØŒ ÙŠØ­ØªØ§Ø¬ Ù…ÙƒØªØ¨Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©.\n"
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ù…Ù† PDF
            text = content.decode('latin-1', errors='ignore')
            words = re.findall(r'[a-zA-ZØ£-ÙŠ\u0600-\u06FF]{3,}', text)
            if words:
                file_content += f"ÙƒÙ„Ù…Ø§Øª Ù…Ø³ØªØ®Ø±Ø¬Ø©: {' '.join(words[:50])}"
        
        elif file_type in ["application/vnd.openxmlformats-officedocument.wordprocessingml.document", 
                          "application/msword"]:
            # Ù…Ù„ÙØ§Øª DOCX/DOC
            file_content = f"Ù…Ù„Ù Word: {file.name}\n"
            file_content += f"Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: {file.size} Ø¨Ø§ÙŠØª\n"
            file_content += "Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª Word Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ØŒ ÙŠØ­ØªØ§Ø¬ Ù…ÙƒØªØ¨Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©.\n"
        
        else:
            # Ø£Ù†ÙˆØ§Ø¹ Ø£Ø®Ø±Ù‰
            try:
                content = file.read()
                if isinstance(content, bytes):
                    file_content = content.decode('utf-8', errors='ignore')
                else:
                    file_content = str(content)
            except:
                file_content = f"Ù…Ù„Ù {file.name} - Ù†ÙˆØ¹ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©"
        
        return file_content.strip()
    
    except Exception as e:
        return f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù {file.name}: {str(e)}"

def search_in_content(query, files_content):
    """Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ ÙÙŠ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„ÙØ§Øª"""
    results = []
    query_words = query.lower().split()
    
    for filename, content in files_content.items():
        if not content:
            continue
        
        content_lower = content.lower()
        
        # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚
        matches = 0
        matched_sentences = []
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ø¬Ù…Ù„
        sentences = re.split(r'[.!?ØŸà¥¤\n]+', content)
        
        for sentence in sentences:
            sentence_lower = sentence.lower().strip()
            if len(sentence_lower) < 10:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                continue
            
            sentence_matches = 0
            for word in query_words:
                if word in sentence_lower:
                    sentence_matches += 1
            
            if sentence_matches > 0:
                matches += sentence_matches
                matched_sentences.append({
                    'sentence': sentence.strip(),
                    'matches': sentence_matches
                })
        
        if matches > 0:
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¬Ù…Ù„ Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ØªØ·Ø§Ø¨Ù‚Ø§Øª
            matched_sentences.sort(key=lambda x: x['matches'], reverse=True)
            
            results.append({
                'filename': filename,
                'total_matches': matches,
                'sentences': matched_sentences[:3],  # Ø£ÙØ¶Ù„ 3 Ø¬Ù…Ù„
                'content_preview': content[:300] + "..." if len(content) > 300 else content
            })
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ØªØ·Ø§Ø¨Ù‚Ø§Øª
    results.sort(key=lambda x: x['total_matches'], reverse=True)
    return results

def generate_real_answer(question, files_content):
    """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„ÙØ§Øª"""
    question_lower = question.lower().strip()
    
    # ØªØ­ÙŠØ©
    if any(word in question_lower for word in ['Ù…Ø±Ø­Ø¨', 'Ù‡Ù„Ø§', 'Ø³Ù„Ø§Ù…', 'Ø£Ù‡Ù„Ø§']):
        return f"""ğŸ¤– **Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ!**

âœ¨ **Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…:**
- Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù„Ù„Ø©: {len(files_content)} Ù…Ù„Ù
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {sum(len(content) for content in files_content.values())} Ø­Ø±Ù
- Ø§Ù„ÙˆÙ‚Øª: {datetime.now().strftime("%H:%M:%S")}

ğŸ“ **Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:**
{chr(10).join([f"â€¢ {filename} ({len(content)} Ø­Ø±Ù)" for filename, content in files_content.items()])}

ğŸ¯ **ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¢Ù†:**
â€¢ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ù…Ù„ÙØ§Øª
â€¢ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø©
â€¢ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ
â€¢ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©

**Ø§Ø³Ø£Ù„ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§ØªÙƒ! ğŸš€**"""
    
    # Ø¥Ø°Ø§ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª
    if not files_content:
        return """âŒ **Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª Ù…Ø­Ù„Ù„Ø© Ù„Ù„Ø¨Ø­Ø« ÙÙŠÙ‡Ø§**

ğŸ“¤ **Ø§Ù„Ø­Ù„:**
1. Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ù†ØµÙŠØ© (TXT Ù…Ø¶Ù…ÙˆÙ†)
2. Ø§Ù†ØªØ¸Ø± Ø±Ø³Ø§Ù„Ø© "ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„"
3. Ø£Ø¹Ø¯ Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ùƒ

ğŸ’¡ **Ù†ØµÙŠØ­Ø©:** Ù…Ù„ÙØ§Øª TXT ØªØ¹Ø·ÙŠ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
    
    # Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙ„Ø®ÙŠØµ
    if any(word in question_lower for word in ['Ù„Ø®Øµ', 'ØªÙ„Ø®ÙŠØµ', 'Ø®Ù„Ø§ØµØ©', 'Ù…Ù„Ø®Øµ']):
        summary = "ğŸ“‹ **Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ:**\n\n"
        
        for filename, content in files_content.items():
            if len(content) > 50:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ 3 Ø¬Ù…Ù„ Ù…Ù‡Ù…Ø©
                sentences = [s.strip() for s in re.split(r'[.!?ØŸà¥¤\n]+', content) if len(s.strip()) > 20]
                top_sentences = sentences[:3] if sentences else ["Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ ÙƒØ§ÙÙŠ"]
                
                summary += f"**ğŸ“„ Ù…Ù† Ù…Ù„Ù {filename}:**\n"
                for i, sentence in enumerate(top_sentences, 1):
                    summary += f"{i}. {sentence}\n"
                summary += "\n"
        
        return summary
    
    # Ø£Ø³Ø¦Ù„Ø© Ø¹Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    if any(word in question_lower for word in ['Ù…Ø­ØªÙˆÙ‰', 'Ù…ÙˆØ¬ÙˆØ¯', 'Ù…ÙƒØªÙˆØ¨', 'Ù†Øµ']):
        content_info = "ğŸ“– **Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ:**\n\n"
        
        for filename, content in files_content.items():
            content_info += f"**ğŸ“„ Ù…Ù„Ù: {filename}**\n"
            content_info += f"â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù: {len(content)}\n"
            content_info += f"â€¢ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {len(content.split())}\n"
            
            if content:
                # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 200 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ
                preview = content[:200] + "..." if len(content) > 200 else content
                content_info += f"â€¢ Ù…Ø¹Ø§ÙŠÙ†Ø©: {preview}\n\n"
            else:
                content_info += "â€¢ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙØ§Ø±Øº Ø£Ùˆ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡ØªÙ‡\n\n"
        
        return content_info
    
    # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ø§Ù…
    search_results = search_in_content(question, files_content)
    
    if search_results:
        answer = f"ğŸ” **Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø¹Ù†:** \"{question}\"\n\n"
        
        for result in search_results[:2]:  # Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬ØªÙŠÙ†
            answer += f"ğŸ“„ **Ù…Ù† Ù…Ù„Ù: {result['filename']}**\n"
            answer += f"â€¢ Ø¹Ø¯Ø¯ Ø§Ù„ØªØ·Ø§Ø¨Ù‚Ø§Øª: {result['total_matches']}\n\n"
            
            answer += "**Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©:**\n"
            for i, sent_data in enumerate(result['sentences'], 1):
                answer += f"{i}. {sent_data['sentence']}\n"
            
            answer += f"\n**Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰:**\n{result['content_preview']}\n\n"
            answer += "---\n"
        
        return answer
    else:
        return f"""ğŸ” **Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†:** "{question}"

âŒ **Ù„Ù… Ø£Ø¬Ø¯ ØªØ·Ø§Ø¨Ù‚Ø§Øª Ù…Ø¨Ø§Ø´Ø±Ø©**

ğŸ“Š **Ù…Ø§ Ø¨Ø­Ø«Øª ÙÙŠÙ‡:**
{chr(10).join([f"â€¢ {filename} ({len(content)} Ø­Ø±Ù)" for filename, content in files_content.items()])}

ğŸ’¡ **Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª:**
- Ø¬Ø±Ø¨ ÙƒÙ„Ù…Ø§Øª Ø£Ø®Ø±Ù‰
- Ø§Ø³Ø£Ù„ "Ù…Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ØŸ" Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ù†ØµÙˆØµ
- Ø§Ø³Ø£Ù„ "Ù„Ø®Øµ Ø§Ù„Ù…Ù„ÙØ§Øª" Ù„Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„"""

def main():
    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
    st.title("ğŸ¤– Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ø°ÙƒÙŠ - ØªØ­Ù„ÙŠÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ")
    st.markdown("### ğŸ“š ØªØ­Ù„ÙŠÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„ÙØ§Øª!")
    
    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        st.header("âš™ï¸ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
        
        # Ø§Ø®ØªØ¨Ø§Ø±
        col1, col2 = st.columns(2)
        with col1:
            if st.button("â•"):
                st.session_state.test_counter += 1
        with col2:
            if st.button("â–"):
                st.session_state.test_counter -= 1
        
        st.metric("ğŸ”¢ Ø§Ù„Ø¹Ø¯Ø§Ø¯", st.session_state.test_counter)
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        st.subheader("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©")
        total_chars = sum(len(content) for content in st.session_state.files_content.values())
        st.metric("ğŸ“ Ù…Ù„ÙØ§Øª Ù…Ø­Ù„Ù„Ø©", len(st.session_state.files_content))
        st.metric("ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø­Ø±Ù", total_chars)
        st.metric("ğŸ’¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", len(st.session_state.chat_history))
        
        # Ù…Ø³Ø­
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ ÙƒÙ„ Ø´ÙŠØ¡"):
            st.session_state.files_content = {}
            st.session_state.processed_files = []
            st.session_state.chat_history = []
            st.success("ØªÙ… Ø§Ù„Ù…Ø³Ø­!")
            st.rerun()
    
    # Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
    st.header("ğŸ“ Ø±ÙØ¹ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª")
    
    uploaded_files = st.file_uploader(
        "Ø§Ø®ØªØ± Ù…Ù„ÙØ§Øª Ù†ØµÙŠØ© (TXT Ù…Ø¶Ù…ÙˆÙ† Ø£ÙƒØ«Ø±)",
        type=['txt', 'pdf', 'docx'],
        accept_multiple_files=True,
        help="Ù…Ù„ÙØ§Øª TXT ØªØ¹Ø·ÙŠ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"
    )
    
    if uploaded_files:
        if st.button("ğŸ”„ ØªØ­Ù„ÙŠÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ù…Ù„ÙØ§Øª", type="primary"):
            progress = st.progress(0)
            
            for i, file in enumerate(uploaded_files):
                progress.progress((i + 1) / len(uploaded_files))
                
                with st.spinner(f"Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ {file.name}..."):
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
                    real_content = extract_text_from_file(file)
                    st.session_state.files_content[file.name] = real_content
                    
                    time.sleep(0.2)  # Ù„Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„ØªÙ‚Ø¯Ù…
            
            st.success("âœ… ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø¨Ù†Ø¬Ø§Ø­!")
            st.rerun()
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù„Ù„Ø©
    if st.session_state.files_content:
        st.header("ğŸ“‹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù„Ù„Ø© (Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ)")
        
        for filename, content in st.session_state.files_content.items():
            with st.expander(f"ğŸ“„ {filename} ({len(content)} Ø­Ø±Ù)"):
                if content and len(content) > 50:
                    st.markdown(f'<div class="file-content">{content[:500]}{"..." if len(content) > 500 else ""}</div>', 
                               unsafe_allow_html=True)
                    
                    if len(content) > 500:
                        if st.button(f"Ø¹Ø±Ø¶ ÙƒØ§Ù…Ù„ Ù„Ù€ {filename}", key=f"full_{filename}"):
                            st.text_area("Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„:", content, height=200, key=f"content_{filename}")
                else:
                    st.warning("Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙØ§Ø±Øº Ø£Ùˆ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡ØªÙ‡")
    
    # Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
    if st.session_state.files_content:
        st.header("ğŸ’¬ Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ")
        
        # Ø£Ø³Ø¦Ù„Ø© Ø³Ø±ÙŠØ¹Ø©
        quick_questions = ["Ù…Ø±Ø­Ø¨Ø§", "Ù„Ø®Øµ Ø§Ù„Ù…Ù„ÙØ§Øª", "Ù…Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ØŸ", "Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ"]
        cols = st.columns(len(quick_questions))
        for i, q in enumerate(quick_questions):
            with cols[i]:
                if st.button(q, key=f"q_{i}"):
                    st.session_state.selected_q = q
        
        # Ø§Ù„Ø³Ø¤Ø§Ù„
        user_question = st.text_area(
            "Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¹Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰:",
            value=st.session_state.get('selected_q', ''),
            placeholder="Ù…Ø«Ø§Ù„: Ø§Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø© Ù…Ø¹ÙŠÙ†Ø©ØŒ Ù„Ø®Øµ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„ØŒ Ù…Ø§ Ø§Ù„Ù…ÙƒØªÙˆØ¨ Ø¹Ù† Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹..."
        )
        
        if st.button("ğŸ” Ø¨Ø­Ø« Ø­Ù‚ÙŠÙ‚ÙŠ", type="primary"):
            if user_question.strip():
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ..."):
                    time.sleep(0.5)
                    
                    # Ø¥Ø¬Ø§Ø¨Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©
                    real_answer = generate_real_answer(user_question, st.session_state.files_content)
                    
                    # Ø­ÙØ¸
                    st.session_state.chat_history.append({
                        "question": user_question,
                        "answer": real_answer,
                        "timestamp": datetime.now().strftime("%H:%M:%S")
                    })
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
                    st.markdown(f'<div class="real-content">{real_answer}</div>', 
                               unsafe_allow_html=True)
            else:
                st.warning("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ø§Ù‹!")
    else:
        st.info("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø£ÙˆÙ„Ø§Ù‹ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ")
    
    # Ø§Ù„ØªØ§Ø±ÙŠØ®
    if st.session_state.chat_history:
        st.header("ğŸ“œ Ø³Ø¬Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©")
        
        for i, chat in enumerate(reversed(st.session_state.chat_history[-3:]), 1):
            with st.expander(f"ğŸ’¬ {chat['question'][:40]}... ({chat['timestamp']})"):
                st.markdown(f"**â“ Ø§Ù„Ø³Ø¤Ø§Ù„:** {chat['question']}")
                st.markdown("**ğŸ“– Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©:**")
                st.markdown(chat['answer'])

if __name__ == "__main__":
    main()
